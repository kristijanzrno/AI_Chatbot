{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovmNgjgQxpw9",
        "colab_type": "code",
        "outputId": "2f9a009d-a4e8-45f7-eb79-46c218cbaeda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        " \n",
        "!pip install tensorflow-datasets==1.2.0\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Tensorflow version {}\".format(tf.__version__))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-datasets==1.2.0 in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.21.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (19.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (5.4.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.21.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.3.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.18.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.12.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (4.38.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (3.10.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==1.2.0) (1.51.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets==1.2.0) (46.0.0)\n",
            "Tensorflow version 2.2.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1gVjiUGyAKC",
        "colab_type": "code",
        "outputId": "5fa291ba-9044-4b7d-89d9-42e45b1a392e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU {}'.format(tpu.cluster_spec().as_dict()['worker']))\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: {}\".format(strategy.num_replicas_in_sync))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU ['10.23.72.74:8470']\n",
            "WARNING:tensorflow:TPU system grpc://10.23.72.74:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.23.72.74:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.72.74:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.23.72.74:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoXl__rOyIRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Maximum sentence length\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "# Maximum number of samples to preprocess\n",
        "MAX_SAMPLES = 90000\n",
        "\n",
        "# For tf.data.Dataset\n",
        "BATCH_SIZE = 64 * strategy.num_replicas_in_sync\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# For Transformer\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "EPOCHS = 200\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiPi4f67zOlF",
        "colab_type": "code",
        "outputId": "876ea236-d500-426d-8f9a-5f8f18890698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "project_path = \"/content/drive/My Drive/data3/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLNDQFTPzZI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.lower().strip()\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  # adding a start and an end token to the sentence\n",
        "  return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekdGg0Fh4Dxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questions = []\n",
        "answers = []\n",
        "with open('/content/drive/My Drive/data2/tbbt2.txt', 'r') as f:\n",
        "  lines = f.readlines()\n",
        "  for line in lines:\n",
        "    l = line.split(' <<<>>> ')\n",
        "    questions.append(preprocess_sentence(l[0]))\n",
        "    answers.append(preprocess_sentence(l[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-dwcktszeZF",
        "colab_type": "code",
        "outputId": "d88dd187-9070-49d0-b70d-99046b5aae8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "\n",
        "print('Sample question: {}'.format(questions[20]))\n",
        "print('Sample answer: {}'.format(answers[20]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample question: oh , hi !\n",
            "Sample answer: hi .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plla3nI-ziUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build tokenizer using tfds for both questions and answers\n",
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size=2**13)\n",
        "\n",
        "# Define start and end token to indicate the start and end of a sentence\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# Vocabulary size plus start and end token\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7j9-jjczl59",
        "colab_type": "code",
        "outputId": "0d49fc87-ad5d-4eac-ef83-367c5cdf860c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(questions[20])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized sample question: [23, 1, 205, 92]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VArzBB_iz1ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize, filter and pad sentences\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # tokenize sentence\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "    # check tokenized sentence max length\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # pad tokenized sentences\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "\n",
        "questions, answers = tokenize_and_filter(questions, answers)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9Edpjzhz6A5",
        "colab_type": "code",
        "outputId": "eb2c9e2d-8534-4155-a229-cfe4c9b1182c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
        "print('Number of samples: {}'.format(len(questions)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 8267\n",
            "Number of samples: 19971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfC58V4Tz9Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decoder inputs use the previous target as input\n",
        "# remove START_TOKEN from targets\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_XtUwLY0DRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzlwZTY60GS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    config.update({\n",
        "        'd_model': self.d_model,\n",
        "        'num_heads': self.num_heads,\n",
        "    })\n",
        "    return config \n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLbqcy3t0Krb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkL3dn4n0P-T",
        "colab_type": "code",
        "outputId": "5220df2e-2ab8-4eea-f125-383e9daed70a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmYQzXgR0Rdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnbJUi690Ut1",
        "colab_type": "code",
        "outputId": "fb045122-1475-4fcd-c408-ba575d8d3d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMMuG7fN0XSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    self.position = position\n",
        "    self.d_model = d_model\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "  \n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    config.update({\n",
        "        'position' : self.position,\n",
        "        'd_model' : self.d_model\n",
        "    })\n",
        "    return config\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW8KHPEP0fNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgUTuYB_0msd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98ukh1FU0ueB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H_TUhL-06iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho5zcq661GUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjGYYdm_1QeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtvoVOvK1VzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    config.update({\n",
        "        'd_model': self.d_model,\n",
        "        'warmup_steps': self.warmup_steps,\n",
        "    })\n",
        "    return config \n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv4l4zVT1aWR",
        "colab_type": "code",
        "outputId": "40fc3191-fad7-4444-b1f6-aa0001910313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMgt9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PDCRPi11ejm",
        "colab_type": "code",
        "outputId": "40e7ab70-e7ca-4778-b398-087a52205a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "# clear backend\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "# initialize and compile model within strategy scope\n",
        "with strategy.scope():\n",
        "  model = transformer(\n",
        "      vocab_size=VOCAB_SIZE,\n",
        "      num_layers=NUM_LAYERS,\n",
        "      units=UNITS,\n",
        "      d_model=D_MODEL,\n",
        "      num_heads=NUM_HEADS,\n",
        "      dropout=DROPOUT)\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Model)                 (None, None, 256)    3170560     inputs[0][0]                     \n",
            "                                                                 enc_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Model)                 (None, None, 256)    3697920     dec_inputs[0][0]                 \n",
            "                                                                 encoder[1][0]                    \n",
            "                                                                 look_ahead_mask[0][0]            \n",
            "                                                                 dec_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "outputs (Dense)                 (None, None, 8267)   2124619     decoder[1][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,993,099\n",
            "Trainable params: 8,993,099\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfibZFbM1kSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.fit(dataset, epochs=EPOCHS)\n",
        "model.load_weights(project_path+'weights_tbbt2_3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCA35LCz2vun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS4ekOVr22mM",
        "colab_type": "code",
        "outputId": "4d29ac3b-518b-4c57-adea-263f502d1371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "output = predict('what are you doing')\n",
        "model.save_weights(project_path+'weights_ds.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: what are you doing\n",
            "Output: i m trying to raise the temperature in here before my nipples tear through my shirt .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}